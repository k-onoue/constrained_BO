{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "import sys\n",
    "from path_info import PROJECT_DIR\n",
    "sys.path.append(PROJECT_DIR)\n",
    "\n",
    "from src.bnn import BayesianMLPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "test_function",
         "type": "scatter",
         "x": [
          -1,
          -0.9899749373433584,
          -0.9799498746867168,
          -0.9699248120300752,
          -0.9598997493734336,
          -0.949874686716792,
          -0.9398496240601504,
          -0.9298245614035088,
          -0.9197994987468672,
          -0.9097744360902256,
          -0.899749373433584,
          -0.8897243107769424,
          -0.8796992481203008,
          -0.8696741854636592,
          -0.8596491228070176,
          -0.849624060150376,
          -0.8395989974937343,
          -0.8295739348370927,
          -0.8195488721804511,
          -0.8095238095238095,
          -0.7994987468671679,
          -0.7894736842105263,
          -0.7794486215538847,
          -0.7694235588972431,
          -0.7593984962406015,
          -0.7493734335839599,
          -0.7393483709273183,
          -0.7293233082706767,
          -0.7192982456140351,
          -0.7092731829573935,
          -0.6992481203007519,
          -0.6892230576441103,
          -0.6791979949874687,
          -0.6691729323308271,
          -0.6591478696741855,
          -0.6491228070175439,
          -0.6390977443609023,
          -0.6290726817042607,
          -0.6190476190476191,
          -0.6090225563909775,
          -0.5989974937343359,
          -0.5889724310776943,
          -0.5789473684210527,
          -0.568922305764411,
          -0.5588972431077694,
          -0.5488721804511278,
          -0.5388471177944862,
          -0.5288220551378446,
          -0.518796992481203,
          -0.5087719298245614,
          -0.4987468671679198,
          -0.4887218045112782,
          -0.4786967418546366,
          -0.468671679197995,
          -0.4586466165413534,
          -0.4486215538847118,
          -0.4385964912280702,
          -0.4285714285714286,
          -0.418546365914787,
          -0.4085213032581454,
          -0.3984962406015038,
          -0.3884711779448622,
          -0.3784461152882206,
          -0.368421052631579,
          -0.3583959899749374,
          -0.3483709273182958,
          -0.33834586466165417,
          -0.32832080200501257,
          -0.31829573934837097,
          -0.30827067669172936,
          -0.29824561403508776,
          -0.28822055137844615,
          -0.27819548872180455,
          -0.26817042606516295,
          -0.25814536340852134,
          -0.24812030075187974,
          -0.23809523809523814,
          -0.22807017543859653,
          -0.21804511278195493,
          -0.20802005012531333,
          -0.19799498746867172,
          -0.18796992481203012,
          -0.17794486215538852,
          -0.1679197994987469,
          -0.1578947368421053,
          -0.1478696741854637,
          -0.1378446115288221,
          -0.1278195488721805,
          -0.1177944862155389,
          -0.10776942355889729,
          -0.09774436090225569,
          -0.08771929824561409,
          -0.07769423558897248,
          -0.06766917293233088,
          -0.057644110275689275,
          -0.04761904761904767,
          -0.03759398496240607,
          -0.027568922305764465,
          -0.01754385964912286,
          -0.007518796992481258,
          0.0025062656641603454,
          0.012531328320801949,
          0.022556390977443552,
          0.032581453634085156,
          0.04260651629072676,
          0.05263157894736836,
          0.06265664160400997,
          0.07268170426065157,
          0.08270676691729317,
          0.09273182957393478,
          0.10275689223057638,
          0.11278195488721798,
          0.12280701754385959,
          0.1328320802005012,
          0.1428571428571428,
          0.1528822055137844,
          0.162907268170426,
          0.1729323308270676,
          0.1829573934837092,
          0.1929824561403508,
          0.20300751879699241,
          0.21303258145363402,
          0.22305764411027562,
          0.23308270676691722,
          0.24310776942355883,
          0.25313283208020043,
          0.26315789473684204,
          0.27318295739348364,
          0.28320802005012524,
          0.29323308270676685,
          0.30325814536340845,
          0.31328320802005005,
          0.32330827067669166,
          0.33333333333333326,
          0.34335839598997486,
          0.35338345864661647,
          0.36340852130325807,
          0.3734335839598997,
          0.3834586466165413,
          0.3934837092731829,
          0.4035087719298245,
          0.4135338345864661,
          0.4235588972431077,
          0.4335839598997493,
          0.4436090225563909,
          0.4536340852130325,
          0.4636591478696741,
          0.4736842105263157,
          0.4837092731829573,
          0.4937343358395989,
          0.5037593984962405,
          0.5137844611528821,
          0.5238095238095237,
          0.5338345864661653,
          0.5438596491228069,
          0.5538847117794485,
          0.5639097744360901,
          0.5739348370927317,
          0.5839598997493733,
          0.593984962406015,
          0.6040100250626566,
          0.6140350877192982,
          0.6240601503759398,
          0.6340852130325814,
          0.644110275689223,
          0.6541353383458646,
          0.6641604010025062,
          0.6741854636591478,
          0.6842105263157894,
          0.694235588972431,
          0.7042606516290726,
          0.7142857142857142,
          0.7243107769423558,
          0.7343358395989974,
          0.744360902255639,
          0.7543859649122806,
          0.7644110275689222,
          0.7744360902255638,
          0.7844611528822054,
          0.794486215538847,
          0.8045112781954886,
          0.8145363408521302,
          0.8245614035087718,
          0.8345864661654134,
          0.844611528822055,
          0.8546365914786966,
          0.8646616541353382,
          0.8746867167919798,
          0.8847117794486214,
          0.894736842105263,
          0.9047619047619047,
          0.9147869674185463,
          0.9248120300751879,
          0.9348370927318295,
          0.9448621553884711,
          0.9548872180451127,
          0.9649122807017543,
          0.9749373433583959,
          0.9849624060150375,
          0.9949874686716791,
          1.0050125313283207,
          1.015037593984962,
          1.025062656641604,
          1.0350877192982457,
          1.045112781954887,
          1.0551378446115285,
          1.0651629072681703,
          1.0751879699248121,
          1.0852130325814535,
          1.095238095238095,
          1.1052631578947367,
          1.1152882205513786,
          1.12531328320802,
          1.1353383458646613,
          1.1453634085213031,
          1.155388471177945,
          1.1654135338345863,
          1.1754385964912277,
          1.1854636591478696,
          1.1954887218045114,
          1.2055137844611528,
          1.2155388471177941,
          1.225563909774436,
          1.2355889724310778,
          1.2456140350877192,
          1.2556390977443606,
          1.2656641604010024,
          1.2756892230576442,
          1.2857142857142856,
          1.295739348370927,
          1.3057644110275688,
          1.3157894736842106,
          1.325814536340852,
          1.3358395989974934,
          1.3458646616541352,
          1.355889724310777,
          1.3659147869674184,
          1.3759398496240598,
          1.3859649122807016,
          1.3959899749373434,
          1.4060150375939848,
          1.4160401002506262,
          1.426065162907268,
          1.4360902255639099,
          1.4461152882205512,
          1.4561403508771926,
          1.4661654135338344,
          1.4761904761904763,
          1.4862155388471177,
          1.496240601503759,
          1.5062656641604009,
          1.5162907268170427,
          1.526315789473684,
          1.5363408521303255,
          1.5463659147869673,
          1.556390977443609,
          1.5664160401002505,
          1.5764411027568919,
          1.5864661654135337,
          1.5964912280701755,
          1.606516290726817,
          1.6165413533834583,
          1.6265664160401,
          1.636591478696742,
          1.6466165413533833,
          1.6566416040100247,
          1.6666666666666665,
          1.6766917293233083,
          1.6867167919799497,
          1.696741854636591,
          1.706766917293233,
          1.7167919799498748,
          1.7268170426065161,
          1.7368421052631575,
          1.7468671679197993,
          1.7568922305764412,
          1.7669172932330826,
          1.776942355889724,
          1.7869674185463658,
          1.7969924812030076,
          1.807017543859649,
          1.8170426065162903,
          1.8270676691729322,
          1.837092731829574,
          1.8471177944862154,
          1.8571428571428568,
          1.8671679197994986,
          1.8771929824561404,
          1.8872180451127818,
          1.8972431077694232,
          1.907268170426065,
          1.9172932330827068,
          1.9273182957393482,
          1.9373433583959896,
          1.9473684210526314,
          1.9573934837092732,
          1.9674185463659146,
          1.977443609022556,
          1.9874686716791978,
          1.9974937343358397,
          2.007518796992481,
          2.0175438596491224,
          2.0275689223057642,
          2.037593984962406,
          2.0476190476190474,
          2.057644110275689,
          2.0676691729323307,
          2.0776942355889725,
          2.087719298245614,
          2.0977443609022552,
          2.107769423558897,
          2.117794486215539,
          2.1278195488721803,
          2.1378446115288217,
          2.1478696741854635,
          2.1578947368421053,
          2.1679197994987467,
          2.177944862155388,
          2.18796992481203,
          2.1979949874686717,
          2.208020050125313,
          2.2180451127819545,
          2.2280701754385963,
          2.238095238095238,
          2.2481203007518795,
          2.258145363408521,
          2.2681704260651627,
          2.2781954887218046,
          2.288220551378446,
          2.2982456140350873,
          2.308270676691729,
          2.318295739348371,
          2.3283208020050123,
          2.3383458646616537,
          2.3483709273182956,
          2.3583959899749374,
          2.3684210526315788,
          2.37844611528822,
          2.388471177944862,
          2.398496240601504,
          2.408521303258145,
          2.4185463659147866,
          2.4285714285714284,
          2.43859649122807,
          2.4486215538847116,
          2.458646616541353,
          2.468671679197995,
          2.4786967418546366,
          2.488721804511278,
          2.4987468671679194,
          2.508771929824561,
          2.518796992481203,
          2.5288220551378444,
          2.538847117794486,
          2.5488721804511276,
          2.5588972431077694,
          2.568922305764411,
          2.578947368421052,
          2.588972431077694,
          2.598997493734336,
          2.6090225563909772,
          2.6190476190476186,
          2.6290726817042605,
          2.6390977443609023,
          2.6491228070175437,
          2.659147869674185,
          2.669172932330827,
          2.6791979949874687,
          2.68922305764411,
          2.6992481203007515,
          2.7092731829573933,
          2.719298245614035,
          2.7293233082706765,
          2.739348370927318,
          2.7493734335839597,
          2.7593984962406015,
          2.769423558897243,
          2.7794486215538843,
          2.789473684210526,
          2.799498746867168,
          2.8095238095238093,
          2.8195488721804507,
          2.8295739348370925,
          2.8395989974937343,
          2.8496240601503757,
          2.859649122807017,
          2.869674185463659,
          2.8796992481203008,
          2.889724310776942,
          2.8997493734335835,
          2.9097744360902253,
          2.919799498746867,
          2.9298245614035086,
          2.93984962406015,
          2.9498746867167918,
          2.9598997493734336,
          2.969924812030075,
          2.9799498746867163,
          2.989974937343358,
          3
         ],
         "y": [
          9,
          8.93995012594142,
          8.880101255645378,
          8.820453389111876,
          8.761006526340916,
          8.701760667332493,
          8.642715812086607,
          8.583871960603261,
          8.525229112882457,
          8.466787268924191,
          8.408546428728462,
          8.350506592295273,
          8.292667759624626,
          8.235029930716516,
          8.177593105570946,
          8.120357284187913,
          8.06332246656742,
          8.00648865270947,
          7.949855842614054,
          7.893424036281178,
          7.837193233710844,
          7.781163434903048,
          7.72533463985779,
          7.66970684857507,
          7.614280061054893,
          7.559054277297254,
          7.504029497302152,
          7.44920572106959,
          7.394582948599569,
          7.340161179892087,
          7.2859404149471425,
          7.231920653764736,
          7.178101896344872,
          7.124484142687547,
          7.0710673927927585,
          7.017851646660509,
          6.964836904290802,
          6.9120231656836335,
          6.859410430839002,
          6.80699869975691,
          6.754787972437359,
          6.702778248880348,
          6.650969529085873,
          6.599361813053937,
          6.547955100784543,
          6.496749392277688,
          6.44574468753337,
          6.394940986551591,
          6.344338289332353,
          6.293936595875655,
          6.243735906181494,
          6.193736220249872,
          6.143937538080791,
          6.09433985967425,
          6.044943185030245,
          5.995747514148779,
          5.946752847029855,
          5.89795918367347,
          5.849366524079623,
          5.800974868248314,
          5.752784216179546,
          5.704794567873319,
          5.657005923329628,
          5.609418282548476,
          5.562031645529865,
          5.514846012273794,
          5.467861382780259,
          5.421077757049264,
          5.37449513508081,
          5.328113516874895,
          5.281932902431517,
          5.235953291750679,
          5.190174684832382,
          5.144597081676624,
          5.099220482283403,
          5.054044886652721,
          5.009070294784581,
          4.964296706678979,
          4.919724122335915,
          4.87535254175539,
          4.831181964937406,
          4.787212391881962,
          4.743443822589055,
          4.699876257058686,
          4.656509695290859,
          4.613344137285571,
          4.57037958304282,
          4.527616032562609,
          4.485053485844938,
          4.442691942889807,
          4.400531403697213,
          4.358571868267158,
          4.316813336599645,
          4.27525580869467,
          4.2338992845522325,
          4.192743764172335,
          4.151789247554978,
          4.11103573470016,
          4.070483225607879,
          4.030131720278138,
          12.47500015703419,
          12.376257058686818,
          12.279523997964837,
          12.18480097486825,
          12.092087989397053,
          12.001385041551247,
          11.912692131330834,
          11.826009258735812,
          11.741336423766183,
          11.658673626421946,
          11.578020866703099,
          11.499378144609645,
          11.422745460141583,
          11.348122813298913,
          11.275510204081634,
          11.204907632489746,
          11.136315098523252,
          11.069732602182148,
          11.005160143466435,
          10.942597722376115,
          10.882045338911189,
          10.823502993071653,
          10.766970684857508,
          10.712448414268755,
          10.659936181305394,
          10.609433985967424,
          10.560941828254848,
          10.514459708167662,
          10.469987625705869,
          10.427525580869467,
          10.387073573658457,
          10.348631604072839,
          10.312199672112612,
          10.277777777777779,
          10.245365921068336,
          10.214964101984284,
          10.186572320525626,
          10.160190576692358,
          10.135818870484481,
          10.113457201901998,
          10.093105570944907,
          10.074763977613205,
          10.058432421906899,
          10.044110903825981,
          10.031799423370456,
          10.021497980540323,
          10.013206575335582,
          10.006925207756233,
          10.002653877802276,
          10.00039258547371,
          10.000141330770536,
          10.001900113692754,
          10.005668934240363,
          10.011447792413364,
          10.019236688211757,
          10.029035621635542,
          10.040844592684719,
          10.054663601359287,
          10.070492647659249,
          10.088331731584601,
          10.108180853135345,
          10.13004001231148,
          10.153909209113008,
          10.179788443539927,
          10.207677715592238,
          10.23757702526994,
          10.269486372573036,
          10.303405757501523,
          10.339335180055402,
          10.377274640234672,
          10.417224138039334,
          10.459183673469388,
          10.503153246524834,
          10.54913285720567,
          10.5971225055119,
          10.64712219144352,
          10.699131915000534,
          10.753151676182938,
          10.809181474990734,
          10.867221311423922,
          10.927271185482503,
          10.989331097166474,
          11.053401046475837,
          11.119481033410594,
          11.187571057970741,
          11.25767112015628,
          11.32978121996721,
          11.403901357403534,
          11.480031532465247,
          11.558171745152354,
          11.638321995464851,
          11.720482283402742,
          11.804652608966023,
          11.890832972154696,
          11.979023372968761,
          12.069223811408218,
          12.161434287473067,
          12.255654801163308,
          12.351885352478941,
          12.450125941419966,
          0.990000062813676,
          0.9701509412629324,
          0.9505028234747271,
          0.931055709449061,
          0.911809599185935,
          0.8927644926853481,
          0.8739203899472996,
          0.8552772909717902,
          0.8368351957588208,
          0.8185941043083906,
          0.8005540166204989,
          0.7827149326951462,
          0.7650768525323336,
          0.74763977613206,
          0.730403703494325,
          0.7133686346191291,
          0.6965345695064732,
          0.6799015081563564,
          0.663469450568778,
          0.6472383967437388,
          0.6312083466812396,
          0.6153793003812795,
          0.599751257843858,
          0.5843242190689756,
          0.569098184056633,
          0.5540731528068297,
          0.5392491253195648,
          0.5246261015948391,
          0.5102040816326533,
          0.4959830654330066,
          0.4819630529958984,
          0.4681440443213295,
          0.45452603940930036,
          0.4411090382598104,
          0.427893040872859,
          0.4148780472484468,
          0.40206405738657436,
          0.3894510712872411,
          0.37703908895044647,
          0.364828110376191,
          0.3528181355644753,
          0.34100916451529867,
          0.3294011972286608,
          0.31799423370456203,
          0.306788273943003,
          0.29578331794398316,
          0.284979365707502,
          0.27437641723356,
          0.26397447252215767,
          0.2537735315732945,
          0.24377359438697008,
          0.23397466096318484,
          0.2243767313019392,
          0.21497980540323272,
          0.20578388326706504,
          0.19678896489343653,
          0.1879950502823476,
          0.17940213943379785,
          0.17101023234778687,
          0.16281932902431512,
          0.15482942946338288,
          0.14704053366498981,
          0.1394526416291356,
          0.13206575335582058,
          0.12487986884504505,
          0.11789498809680869,
          0.11111111111111122,
          0.10452823788795292,
          0.0981463684273341,
          0.09196550272925444,
          0.0859856407937137,
          0.08020678262071214,
          0.07462892821025002,
          0.06925207756232707,
          0.06407623067694306,
          0.059101387554098245,
          0.054327548193792825,
          0.049754712596026575,
          0.045382880760799306,
          0.04121205268811123,
          0.03724222837796251,
          0.033473407830352964,
          0.029905591045282433,
          0.02653877802275109,
          0.023372968762759076,
          0.020408163265306232,
          0.01764436153039244,
          0.015081563558017836,
          0.012719769348182523,
          0.01055897890088638,
          0.008599192216129325,
          0.006840409293911461,
          0.005282630134232849,
          0.003925854737093408,
          0.002770083102493092,
          0.0018153152304319648,
          0.0010615511209100552,
          0.0005087907739273169,
          0.00015703418948373856,
          0.000006281367579349097,
          0.00005653230821414187,
          0.00030778701138810575,
          0.0007600454771012652,
          0.0014133077053536136,
          0.0022675736961451087,
          0.0033228434494757745,
          0.004579116965345672,
          0.006036394243754758,
          0.0076946752847029554,
          0.009553960088190323,
          0.011614248654216959,
          0.013875540982782783,
          0.01633783707388768,
          0.019001136927531755,
          0.021865440543715125,
          0.02493074792243769,
          0.02819705906369929,
          0.03166437396750006,
          0.035332692633840174,
          0.039202015062719475,
          0.04327234125413778,
          0.04754367120809525,
          0.0520160049245921,
          0.056689342403628135,
          0.06156368364520314,
          0.06663902864931733,
          0.07191537741597091,
          0.07739272994516368,
          0.0830710862368954,
          0.08895044629116627,
          0.0950308101079766,
          0.1013121776873261,
          0.10779454902921452,
          0.1144779241336421,
          0.12136230300060916,
          0.1284476856301154,
          0.13573407202216053,
          0.1432214621767448,
          0.15090985609386862,
          0.1587992537735316,
          0.1668896552157334,
          0.1751810604204744,
          0.18367346938775495,
          0.19236688211757466,
          0.2012612986099332,
          0.21035671886483087,
          0.21965314288226814,
          0.22915057066224462,
          0.23884900220475982,
          0.24874843750981424,
          0.25884887657740824,
          0.2691503194075414,
          0.2796527660002134,
          0.29035621635542447,
          0.30126067047317523,
          0.31236612835346517,
          0.3236725899962938,
          0.33518005540166157,
          0.34688852456956903,
          0.35879799750001573,
          0.37090847419300105,
          0.38321995464852554,
          0.39573243886658976,
          0.4084459268471932,
          0.42136041859033524,
          0.43447591409601644,
          0.44779241336423736,
          0.4613099163949975,
          0.4750284231882963,
          0.4889479337441342,
          0.5030684480625118,
          0.5173899661434288,
          0.5319124879868842,
          0.5466360135928788,
          0.5615605429614132,
          0.5766860760924869,
          0.592012612986099,
          0.6075401536422503,
          0.6232686980609415,
          0.6391982462421718,
          0.6553287981859407,
          0.6716603538922488,
          0.6881929133610967,
          0.7049264765924838,
          0.7218610435864092,
          0.738996614342874,
          0.7563331888618786,
          0.7738707671434225,
          0.7916093491875047,
          0.8095489349941262,
          0.8276895245632875,
          0.8460311178949881,
          0.8645737149892271,
          0.8833173158460051,
          0.9022619204653233,
          0.9214075288471806,
          0.9407541409915763,
          0.960301756898511,
          0.980050376567986,
          1
         ]
        }
       ],
       "layout": {
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Plot of the test_function"
        },
        "xaxis": {
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "title": {
          "text": "test_function(x)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Define the test function\n",
    "def test_function(x):\n",
    "    if 0 <= x <= 1:\n",
    "        return 10 + 10 * (x - 0.5)**2  # High penalty within [0, 1]\n",
    "    else:\n",
    "        return (x - 2)**2  # Quadratic function with a minimum at x = 2\n",
    "\n",
    "# Generate x values\n",
    "x_values = np.linspace(-1, 3, 400)\n",
    "y_values = [test_function(x) for x in x_values]\n",
    "\n",
    "# Create the plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_values, y=y_values, mode='lines', name='test_function'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Plot of the test_function\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"test_function(x)\",\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "diag(): Supports 1D or 2D tensors. Got 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 153\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Perform optimization\u001b[39;00m\n\u001b[1;32m    152\u001b[0m bounds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0.0\u001b[39m], [\u001b[38;5;241m4.0\u001b[39m]])\n\u001b[0;32m--> 153\u001b[0m candidate, acq_value \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Optimal candidate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcandidate\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Obtain new data point\u001b[39;00m\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/botorch/optim/optimize.py:543\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[1;32m    521\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[1;32m    522\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[1;32m    523\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[1;32m    542\u001b[0m )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/botorch/optim/optimize.py:564\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[0;32m--> 564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/botorch/optim/optimize.py:255\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    252\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[38;5;241m.\u001b[39mbatch_initial_conditions\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# pyre-ignore[28]: Unexpected keyword argument `acq_function` to anonymous call.\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m \u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ic_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_restarts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mic_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m batch_limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    270\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m     ),\n\u001b[1;32m    275\u001b[0m )\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_batch_candidates\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor, List[\u001b[38;5;167;01mWarning\u001b[39;00m]]:\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/botorch/optim/initializers.py:418\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints, generator, fixed_X_fantasies)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start_idx \u001b[38;5;241m<\u001b[39m X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    417\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m batch_limit, X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 418\u001b[0m     Y_rnd_curr \u001b[38;5;241m=\u001b[39m \u001b[43macq_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_rnd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    421\u001b[0m     Y_rnd_list\u001b[38;5;241m.\u001b[39mappend(Y_rnd_curr)\n\u001b[1;32m    422\u001b[0m     start_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_limit\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/botorch/utils/transforms.py:288\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    287\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 288\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(acqf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_ensemble(acqf\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# IDEA: this could be wrapped into SampleReducingMCAcquisitionFunction\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    292\u001b[0m         output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acqf\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    293\u001b[0m     )\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/botorch/acquisition/analytic.py:796\u001b[0m, in \u001b[0;36mUpperConfidenceBound.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;129m@t_batch_mode_transform\u001b[39m(expected_q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    787\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the Upper Confidence Bound on the candidate set X.\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \n\u001b[1;32m    789\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;124;03m        given design points `X`.\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m     mean, sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean_and_sigma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (mean \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mmean) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m*\u001b[39m sigma\n",
      "File \u001b[0;32m~/ws/constrained_BO/bo-env/lib/python3.12/site-packages/botorch/acquisition/analytic.py:101\u001b[0m, in \u001b[0;36mAnalyticAcquisitionFunction._mean_and_sigma\u001b[0;34m(self, X, compute_sigma, min_var)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the first and second moments of the model posterior.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    returns a single tensor of means if compute_sigma is True.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# ensures buffers / parameters are on the same device\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposterior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_transform\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m mean \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# removing redundant dimensions\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compute_sigma:\n",
      "Cell \u001b[0;32mIn[3], line 90\u001b[0m, in \u001b[0;36mBayesianMLPModel.posterior\u001b[0;34m(self, X, observation_noise, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m pred_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbayesian_mlp(X)\n\u001b[1;32m     89\u001b[0m mean \u001b[38;5;241m=\u001b[39m pred_dist\u001b[38;5;241m.\u001b[39mmean\n\u001b[0;32m---> 90\u001b[0m covar \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MultivariateNormal(mean, covar)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: diag(): Supports 1D or 2D tensors. Got 3D"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "from botorch.models.model import Model\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "\n",
    "class BayesianLinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BayesianLinearRegression, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Parameters for the prior distributions of weights and biases\n",
    "        self.w_mu = nn.Parameter(torch.zeros(input_dim, output_dim))\n",
    "        self.w_log_sigma = nn.Parameter(torch.zeros(input_dim, output_dim))\n",
    "        self.b_mu = nn.Parameter(torch.zeros(output_dim))\n",
    "        self.b_log_sigma = nn.Parameter(torch.zeros(output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w_sigma = torch.exp(self.w_log_sigma)\n",
    "        b_sigma = torch.exp(self.b_log_sigma)\n",
    "        \n",
    "        # Sampling weights and biases\n",
    "        w = self.w_mu + w_sigma * torch.randn_like(self.w_mu)\n",
    "        b = self.b_mu + b_sigma * torch.randn_like(self.b_mu)\n",
    "        \n",
    "        return torch.matmul(x, w) + b\n",
    "    \n",
    "    def predict_dist(self, x):\n",
    "        y = self.forward(x)\n",
    "        \n",
    "        # Calculating the uncertainty of the output\n",
    "        w_sigma = torch.exp(self.w_log_sigma)\n",
    "        b_sigma = torch.exp(self.b_log_sigma)\n",
    "        \n",
    "        # Calculating the standard deviation considering the uncertainty of weights and biases\n",
    "        output_sigma = torch.sqrt(torch.matmul(x**2, w_sigma**2) + b_sigma**2)\n",
    "        \n",
    "        return Normal(y, output_sigma)\n",
    "\n",
    "\n",
    "class BayesianMLP(nn.Module):\n",
    "    def __init__(self, input_dim, min_val=None, max_val=None):\n",
    "        super(BayesianMLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_dim, 64)\n",
    "        self.hidden2 = nn.Linear(64, 64)\n",
    "        self.hidden3 = nn.Linear(64, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bayesian_output = BayesianLinearRegression(64, 1)\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.relu(self.hidden3(x))\n",
    "        \n",
    "        # Get output from Bayesian linear regression\n",
    "        y_dist = self.bayesian_output.predict_dist(x)\n",
    "\n",
    "        if self.min_val is not None or self.max_val is not None:\n",
    "            # Clamp the output\n",
    "            y_mean = torch.clamp(y_dist.mean, min=self.min_val, max=self.max_val)\n",
    "        else:\n",
    "            y_mean = y_dist.mean\n",
    "\n",
    "        y_stddev = y_dist.stddev  # Keep the standard deviation as it is\n",
    "        \n",
    "        # Return new distribution\n",
    "        return Normal(y_mean, y_stddev)\n",
    "\n",
    "\n",
    "class BayesianMLPModel(Model):\n",
    "    def __init__(self, input_dim, min_val=None, max_val=None):\n",
    "        super().__init__()\n",
    "        self.bayesian_mlp = BayesianMLP(input_dim, min_val, max_val)\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "        self._num_outputs = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bayesian_mlp(x)\n",
    "    \n",
    "    def posterior(self, X, observation_noise=False, **kwargs):\n",
    "        pred_dist = self.bayesian_mlp(X)\n",
    "        mean = pred_dist.mean\n",
    "        covar = torch.diag(pred_dist.stddev**2)\n",
    "        return MultivariateNormal(mean, covar)\n",
    "    \n",
    "    @property\n",
    "    def num_outputs(self):\n",
    "        return self._num_outputs\n",
    "    \n",
    "    @property\n",
    "    def train_inputs(self):\n",
    "        return self._train_inputs\n",
    "\n",
    "    @property\n",
    "    def train_targets(self):\n",
    "        return self._train_targets\n",
    "\n",
    "    def set_train_data(self, inputs=None, targets=None, strict=True):\n",
    "        self._train_inputs = inputs\n",
    "        self._train_targets = targets\n",
    "\n",
    "\n",
    "# Define the test function\n",
    "def test_function(x):\n",
    "    if 0 <= x <= 1:\n",
    "        return 10 + 10 * (x - 0.5)**2  # High penalty within [0, 1]\n",
    "    else:\n",
    "        return (x - 2)**2  # Quadratic function with a minimum at x = 2\n",
    "\n",
    "# Convert test_function to a PyTorch tensor\n",
    "def objective(x):\n",
    "    return torch.tensor([test_function(xi.item()) for xi in x], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train_model(model, train_X, train_Y, num_epochs=1000, learning_rate=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output_dist = model(train_X)\n",
    "        loss = -output_dist.log_prob(train_Y).mean()  # Minimize negative log likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create initial data points\n",
    "train_X = torch.rand(10, 1) * 4  # Generate 10 random initial points in the range [0, 4)\n",
    "train_Y = torch.tensor([test_function(xi.item()) for xi in train_X], dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Optimization loop\n",
    "for i in range(100):\n",
    "    # Define and fit the model\n",
    "    model = BayesianMLPModel(input_dim=1)\n",
    "    model.set_train_data(train_X, train_Y)\n",
    "    model = train_model(model, train_X, train_Y)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Define the acquisition function\n",
    "    acq_func = UpperConfidenceBound(model, beta=0.1)\n",
    "    \n",
    "    # Perform optimization\n",
    "    bounds = torch.tensor([[0.0], [4.0]])\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=5,\n",
    "        raw_samples=20,\n",
    "    )\n",
    "    \n",
    "    print(f\"Iteration {i+1}, Optimal candidate: {candidate.item()}\")\n",
    "    \n",
    "    # Obtain new data point\n",
    "    new_x = candidate\n",
    "    new_y = torch.tensor([test_function(new_x.item())], dtype=torch.float32).unsqueeze(-1)\n",
    "    \n",
    "    # Update data\n",
    "    train_X = torch.cat([train_X, new_x.unsqueeze(0)])\n",
    "    train_Y = torch.cat([train_Y, new_y])\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"hellooooo\")\n",
    "print(train_X[train_Y.argmin().item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Optimal candidate: 0.0\n",
      "Iteration 2, Optimal candidate: 0.0\n",
      "Iteration 3, Optimal candidate: 0.0\n",
      "Iteration 4, Optimal candidate: 0.0\n",
      "Iteration 5, Optimal candidate: 0.0\n",
      "Iteration 6, Optimal candidate: 0.0\n",
      "Iteration 7, Optimal candidate: 0.0\n",
      "Iteration 8, Optimal candidate: 0.0\n",
      "Iteration 9, Optimal candidate: 0.0\n",
      "Iteration 10, Optimal candidate: 0.0\n",
      "Iteration 11, Optimal candidate: 0.080141082406044\n",
      "Iteration 12, Optimal candidate: 0.0\n",
      "Iteration 13, Optimal candidate: 0.12079741060733795\n",
      "Iteration 14, Optimal candidate: 0.0\n",
      "Iteration 15, Optimal candidate: 0.17396406829357147\n",
      "Iteration 16, Optimal candidate: 0.0\n",
      "Iteration 17, Optimal candidate: 0.18600159883499146\n",
      "Iteration 18, Optimal candidate: 0.0\n",
      "Iteration 19, Optimal candidate: 0.0\n",
      "Iteration 20, Optimal candidate: 0.0\n",
      "Iteration 21, Optimal candidate: 0.0\n",
      "Iteration 22, Optimal candidate: 0.0\n",
      "Iteration 23, Optimal candidate: 0.0\n",
      "Iteration 24, Optimal candidate: 0.8540904521942139\n",
      "Iteration 25, Optimal candidate: 0.1862332820892334\n",
      "Iteration 26, Optimal candidate: 0.11264406889677048\n",
      "Iteration 27, Optimal candidate: 0.0\n",
      "Iteration 28, Optimal candidate: 0.03817695379257202\n",
      "Iteration 29, Optimal candidate: 0.04913860559463501\n",
      "Iteration 30, Optimal candidate: 0.08667747676372528\n",
      "Iteration 31, Optimal candidate: 0.10015096515417099\n",
      "Iteration 32, Optimal candidate: 0.09759648144245148\n",
      "Iteration 33, Optimal candidate: 0.08256542682647705\n",
      "Iteration 34, Optimal candidate: 0.9719547033309937\n",
      "Iteration 35, Optimal candidate: 0.07201433926820755\n",
      "Iteration 36, Optimal candidate: 0.9165206551551819\n",
      "Iteration 37, Optimal candidate: 0.992155909538269\n",
      "Iteration 38, Optimal candidate: 0.021805910393595695\n",
      "Iteration 39, Optimal candidate: 1.0572478771209717\n",
      "Iteration 40, Optimal candidate: 0.8835490942001343\n",
      "Iteration 41, Optimal candidate: 0.025787897408008575\n",
      "Iteration 42, Optimal candidate: 0.0\n",
      "Iteration 43, Optimal candidate: 0.01874512806534767\n",
      "Iteration 44, Optimal candidate: 0.027028679847717285\n",
      "Iteration 45, Optimal candidate: 0.06741556525230408\n",
      "Iteration 46, Optimal candidate: 0.16742247343063354\n",
      "Iteration 47, Optimal candidate: 0.8954932689666748\n",
      "Iteration 48, Optimal candidate: 0.0\n",
      "Iteration 49, Optimal candidate: 0.0\n",
      "Iteration 50, Optimal candidate: 0.06579451262950897\n",
      "Iteration 51, Optimal candidate: 0.8684694766998291\n",
      "Iteration 52, Optimal candidate: 0.1144682839512825\n",
      "Iteration 53, Optimal candidate: 0.0\n",
      "Iteration 54, Optimal candidate: 0.11525226384401321\n",
      "Iteration 55, Optimal candidate: 0.9682455658912659\n",
      "Iteration 56, Optimal candidate: 0.0\n",
      "Iteration 57, Optimal candidate: 1.0102031230926514\n",
      "Iteration 58, Optimal candidate: 0.0\n",
      "Iteration 59, Optimal candidate: 1.0250542163848877\n",
      "Iteration 60, Optimal candidate: 0.9475226402282715\n",
      "Iteration 61, Optimal candidate: 0.08548228442668915\n",
      "Iteration 62, Optimal candidate: 0.8376471996307373\n",
      "Iteration 63, Optimal candidate: 0.17196114361286163\n",
      "Iteration 64, Optimal candidate: 0.7819665670394897\n",
      "Iteration 65, Optimal candidate: 0.0\n",
      "Iteration 66, Optimal candidate: 0.915715217590332\n",
      "Iteration 67, Optimal candidate: 0.0\n",
      "Iteration 68, Optimal candidate: 0.2270156890153885\n",
      "Iteration 69, Optimal candidate: 1.0748467445373535\n",
      "Iteration 70, Optimal candidate: 0.15096154808998108\n",
      "Iteration 71, Optimal candidate: 0.054002322256565094\n",
      "Iteration 72, Optimal candidate: 0.962693989276886\n",
      "Iteration 73, Optimal candidate: 0.007644671481102705\n",
      "Iteration 74, Optimal candidate: 0.2058369368314743\n",
      "Iteration 75, Optimal candidate: 0.0\n",
      "Iteration 76, Optimal candidate: 0.0\n",
      "Iteration 77, Optimal candidate: 0.0\n",
      "Iteration 78, Optimal candidate: 0.0\n",
      "Iteration 79, Optimal candidate: 0.8033801317214966\n",
      "Iteration 80, Optimal candidate: 0.016383454203605652\n",
      "Iteration 81, Optimal candidate: 0.9373414516448975\n",
      "Iteration 82, Optimal candidate: 0.0\n",
      "Iteration 83, Optimal candidate: 0.9954361915588379\n",
      "Iteration 84, Optimal candidate: 0.8912292122840881\n",
      "Iteration 85, Optimal candidate: 0.0\n",
      "Iteration 86, Optimal candidate: 0.0\n",
      "Iteration 87, Optimal candidate: 0.0\n",
      "Iteration 88, Optimal candidate: 0.037542540580034256\n",
      "Iteration 89, Optimal candidate: 0.9115771055221558\n",
      "Iteration 90, Optimal candidate: 0.0011234581470489502\n",
      "Iteration 91, Optimal candidate: 0.0\n",
      "Iteration 92, Optimal candidate: 0.0\n",
      "Iteration 93, Optimal candidate: 0.052006032317876816\n",
      "Iteration 94, Optimal candidate: 0.2662320137023926\n",
      "Iteration 95, Optimal candidate: 0.0\n",
      "Iteration 96, Optimal candidate: 0.0\n",
      "Iteration 97, Optimal candidate: 0.8010679483413696\n",
      "Iteration 98, Optimal candidate: 0.9290403723716736\n",
      "Iteration 99, Optimal candidate: 0.0\n",
      "Iteration 100, Optimal candidate: 0.08846433460712433\n",
      "\n",
      "\n",
      "\n",
      "hellooooo\n",
      "tensor([2.3110])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "from botorch.models.model import Model\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "\n",
    "class BayesianLinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BayesianLinearRegression, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Parameters for the prior distributions of weights and biases\n",
    "        self.w_mu = nn.Parameter(torch.zeros(input_dim, output_dim))\n",
    "        self.w_log_sigma = nn.Parameter(torch.zeros(input_dim, output_dim))\n",
    "        self.b_mu = nn.Parameter(torch.zeros(output_dim))\n",
    "        self.b_log_sigma = nn.Parameter(torch.zeros(output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w_sigma = torch.exp(self.w_log_sigma)\n",
    "        b_sigma = torch.exp(self.b_log_sigma)\n",
    "        \n",
    "        # Sampling weights and biases\n",
    "        w = self.w_mu + w_sigma * torch.randn_like(self.w_mu)\n",
    "        b = self.b_mu + b_sigma * torch.randn_like(self.b_mu)\n",
    "        \n",
    "        return torch.matmul(x, w) + b\n",
    "    \n",
    "    def predict_dist(self, x):\n",
    "        y = self.forward(x)\n",
    "        \n",
    "        # Calculating the uncertainty of the output\n",
    "        w_sigma = torch.exp(self.w_log_sigma)\n",
    "        b_sigma = torch.exp(self.b_log_sigma)\n",
    "        \n",
    "        # Calculating the standard deviation considering the uncertainty of weights and biases\n",
    "        output_sigma = torch.sqrt(torch.matmul(x**2, w_sigma**2) + b_sigma**2)\n",
    "        \n",
    "        return Normal(y, output_sigma)\n",
    "\n",
    "\n",
    "class BayesianMLP(nn.Module):\n",
    "    def __init__(self, input_dim, min_val=None, max_val=None):\n",
    "        super(BayesianMLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_dim, 64)\n",
    "        self.hidden2 = nn.Linear(64, 64)\n",
    "        self.hidden3 = nn.Linear(64, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bayesian_output = BayesianLinearRegression(64, 1)\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        x = self.relu(self.hidden3(x))\n",
    "        \n",
    "        # Get output from Bayesian linear regression\n",
    "        y_dist = self.bayesian_output.predict_dist(x)\n",
    "\n",
    "        if self.min_val is not None or self.max_val is not None:\n",
    "            # Clamp the output\n",
    "            y_mean = torch.clamp(y_dist.mean, min=self.min_val, max=self.max_val)\n",
    "        else:\n",
    "            y_mean = y_dist.mean\n",
    "\n",
    "        y_stddev = y_dist.stddev  # Keep the standard deviation as it is\n",
    "        \n",
    "        # Return new distribution\n",
    "        return Normal(y_mean, y_stddev)\n",
    "\n",
    "\n",
    "class BayesianMLPModel(Model):\n",
    "    def __init__(self, input_dim, min_val=None, max_val=None):\n",
    "        super().__init__()\n",
    "        self.bayesian_mlp = BayesianMLP(input_dim, min_val, max_val)\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "        self._num_outputs = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bayesian_mlp(x)\n",
    "    \n",
    "    def posterior(self, X, observation_noise=False, **kwargs):\n",
    "        pred_dist = self.bayesian_mlp(X)\n",
    "        mean = pred_dist.mean.squeeze(-1)  # Ensure mean is 2D\n",
    "        stddev = pred_dist.stddev.squeeze(-1)  # Ensure stddev is 2D\n",
    "        covar = torch.diag_embed(stddev**2)\n",
    "        return MultivariateNormal(mean, covar)\n",
    "    \n",
    "    @property\n",
    "    def num_outputs(self):\n",
    "        return self._num_outputs\n",
    "    \n",
    "    @property\n",
    "    def train_inputs(self):\n",
    "        return self._train_inputs\n",
    "\n",
    "    @property\n",
    "    def train_targets(self):\n",
    "        return self._train_targets\n",
    "\n",
    "    def set_train_data(self, inputs=None, targets=None, strict=True):\n",
    "        self._train_inputs = inputs\n",
    "        self._train_targets = targets\n",
    "\n",
    "\n",
    "# Define the test function\n",
    "def test_function(x):\n",
    "    if 0 <= x <= 1:\n",
    "        return 10 + 10 * (x - 0.5)**2  # High penalty within [0, 1]\n",
    "    else:\n",
    "        return (x - 2)**2  # Quadratic function with a minimum at x = 2\n",
    "\n",
    "# Convert test_function to a PyTorch tensor\n",
    "def objective(x):\n",
    "    return torch.tensor([test_function(xi.item()) for xi in x], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train_model(model, train_X, train_Y, num_epochs=1000, learning_rate=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output_dist = model(train_X)\n",
    "        loss = -output_dist.log_prob(train_Y).mean()  # Minimize negative log likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create initial data points\n",
    "train_X = torch.rand(10, 1) * 4  # Generate 10 random initial points in the range [0, 4)\n",
    "train_Y = torch.tensor([test_function(xi.item()) for xi in train_X], dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Optimization loop\n",
    "for i in range(100):\n",
    "    # Define and fit the model\n",
    "    model = BayesianMLPModel(input_dim=1)\n",
    "    model.set_train_data(train_X, train_Y)\n",
    "    model = train_model(model, train_X, train_Y)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Define the acquisition function\n",
    "    acq_func = UpperConfidenceBound(model, beta=0.1)\n",
    "    \n",
    "    # Perform optimization\n",
    "    bounds = torch.tensor([[0.0], [4.0]])\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=5,\n",
    "        raw_samples=20,\n",
    "    )\n",
    "    \n",
    "    print(f\"Iteration {i+1}, Optimal candidate: {candidate.item()}\")\n",
    "    \n",
    "    # Obtain new data point\n",
    "    new_x = candidate\n",
    "    new_y = torch.tensor([test_function(new_x.item())], dtype=torch.float32).unsqueeze(-1)\n",
    "    \n",
    "    # Update data\n",
    "    train_X = torch.cat([train_X, new_x])\n",
    "    train_Y = torch.cat([train_Y, new_y])\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"hellooooo\")\n",
    "print(train_X[train_Y.argmin().item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
